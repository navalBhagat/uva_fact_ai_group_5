#!/bin/bash

#SBATCH --partition=gpu_mig
#SBATCH --gpus=1
#SBATCH --job-name=t12_c32_r32
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=8
#SBATCH --time=8:00:00
#SBATCH --output=slurm_output_%A.out

module purge
module load 2024
module load Anaconda3/2024.06-1

source activate ldm
cd ~/fact/dp_lora
mkdir -p output/table12

srun python ./sampling/unconditional_sampling.py \
    --yaml ./reproducibility_experiments/finetuning/celeba32-dp-eps10-rank32.yaml \
    --ckpt <PATH_TO_CELEBA32_R32_CKPT> \
    -o output/table12/celeba32_r32.pt \
    --num_samples 60000 \
    --batch_size 300
