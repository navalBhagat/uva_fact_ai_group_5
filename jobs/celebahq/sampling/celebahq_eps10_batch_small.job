#!/bin/bash

#SBATCH --partition=gpu_a100
#SBATCH --gpus=2
#SBATCH --job-name=smp_b4
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=8
#SBATCH --time=8:00:00
#SBATCH --output=slurm/b5/slurm_output_%A.out

module purge
module load 2024
module load Anaconda3/2024.06-1

source activate ldm
cd ~/fact/dp_lora

export PYTHONPATH="${PYTHONPATH}:${PWD}"

srun python ./sampling/conditional_sampling.py \
    --yaml ./reproducibility_experiments/backup/celebahq-eps10-batch-small.yaml \
    --ckpt /home/scur0003/fact/dp_lora/logs/backup/celebahq/<>/checkpoints/last.ckpt \
    --output output/backup/celebahq_eps10_batch_small.pt \
    --num_samples 50000 \
    --batch_size 200 \
    --decoder_batch_size 25 \
    --classes 0 1
